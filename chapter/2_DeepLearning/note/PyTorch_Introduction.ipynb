{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi_QP1bmMThC"
   },
   "source": [
    "Today, we will be intoducing PyTorch, \"an open source deep learning platform that provides a seamless path from research prototyping to production deployment\".\n",
    "今天，我们将介绍PyTorch，“一个开源深度学习平台，它提供了一种无缝方式可将研究原型转化到产品部署”\n",
    "\n",
    "Goal takeaways (要点): \n",
    "- Automatic differentiation is a powerful tool\n",
    "- PyTorch implements common functions used in deep learning\n",
    "- Data Processing with PyTorch DataSet\n",
    "- Mixed Presision Training in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "RQIPkkKdMThD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(446)\n",
    "np.random.seed(446)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCQTBsnWMThH"
   },
   "source": [
    "## Tensors and relation to numpy\n",
    "\n",
    "By this point, we have worked with numpy quite a bit. PyTorch's basic building block, the `tensor` is similar to numpy's `ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "IXnFLFr1MThI",
    "outputId": "9eb2c156-0c35-4e11-d388-f3c20edc5e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_numpy, x_torch\n",
      "[0.1 0.2 0.3] tensor([0.1000, 0.2000, 0.3000])\n",
      "\n",
      "to and from numpy and pytorch\n",
      "tensor([0.1000, 0.2000, 0.3000], dtype=torch.float64) [0.1 0.2 0.3]\n",
      "\n",
      "x+y\n",
      "[3.1 4.2 5.3] tensor([3.1000, 4.2000, 5.3000])\n",
      "\n",
      "norm\n",
      "0.37416573867739417 tensor(0.3742)\n",
      "\n",
      "mean along the 0th dimension\n",
      "[2. 3.] tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# we create tensors in a similar way to numpy nd arrays\n",
    "x_numpy = np.array([0.1, 0.2, 0.3])\n",
    "x_torch = torch.tensor([0.1, 0.2, 0.3])\n",
    "print('x_numpy, x_torch')\n",
    "print(x_numpy, x_torch)\n",
    "print()\n",
    "\n",
    "# to and from numpy, pytorch\n",
    "print('to and from numpy and pytorch')\n",
    "print(torch.from_numpy(x_numpy), x_torch.numpy())\n",
    "print()\n",
    "\n",
    "# we can do basic operations like +-*/\n",
    "y_numpy = np.array([3,4,5.])\n",
    "y_torch = torch.tensor([3,4,5.])\n",
    "print(\"x+y\")\n",
    "print(x_numpy + y_numpy, x_torch + y_torch)\n",
    "print()\n",
    "\n",
    "# many functions that are in numpy are also in pytorch\n",
    "print(\"norm\")\n",
    "print(np.linalg.norm(x_numpy), torch.norm(x_torch))\n",
    "print()\n",
    "\n",
    "# to apply an operation along a dimension,\n",
    "# we use the dim keyword argument instead of axis\n",
    "print(\"mean along the 0th dimension\")\n",
    "x_numpy = np.array([[1,2],[3,4.]])\n",
    "x_torch = torch.tensor([[1,2],[3,4.]])\n",
    "print(np.mean(x_numpy, axis=0), torch.mean(x_torch, dim=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtyttsoZMThL"
   },
   "source": [
    "### Tensor.view\n",
    "We can use the `Tensor.view()` function to reshape tensors similarly to `numpy.reshape()`\n",
    "\n",
    "It can also automatically calculate the correct dimension if a `-1` is passed in. This is useful if we are working with batches, but the batch size is unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "ABhZ5mKpMThM",
    "outputId": "312318b2-7ba9-4867-f289-141f09786ee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 4.1549e-01,  1.2418e+00, -5.9652e-02,  ..., -1.2715e+00,\n",
      "            3.2162e-01, -2.1700e-01],\n",
      "          [ 1.0059e-01, -2.7410e-01,  6.0636e-01,  ...,  4.6824e-01,\n",
      "            5.6736e-01,  7.5577e-01],\n",
      "          [-4.8186e-01,  5.0016e-01,  3.2022e-01,  ...,  7.3162e-01,\n",
      "           -5.3114e-01,  5.8301e-01],\n",
      "          ...,\n",
      "          [ 1.8210e+00, -1.1465e-01, -1.2788e+00,  ..., -1.6201e-01,\n",
      "           -2.7692e+00, -2.5014e-01],\n",
      "          [ 4.4369e-01,  8.8837e-02, -7.9332e-01,  ...,  1.3867e+00,\n",
      "           -7.6429e-02, -2.7608e-01],\n",
      "          [ 7.7107e-02, -1.8573e-01, -1.4080e+00,  ..., -9.7084e-01,\n",
      "           -1.2470e+00, -2.5729e-01]],\n",
      "\n",
      "         [[ 1.0295e+00,  3.3301e-01,  6.9952e-01,  ...,  1.4918e+00,\n",
      "           -9.3303e-01, -6.5883e-02],\n",
      "          [ 1.0721e+00,  4.3090e-01,  7.3455e-01,  ..., -6.0992e-01,\n",
      "            8.8309e-01, -6.9214e-01],\n",
      "          [ 2.9637e-01, -4.8557e-01,  6.7689e-01,  ...,  1.3190e+00,\n",
      "            7.3534e-01, -5.9384e-01],\n",
      "          ...,\n",
      "          [ 6.5153e-01, -6.0284e-01,  1.1990e+00,  ..., -9.4026e-01,\n",
      "            6.7833e-01,  3.7064e-01],\n",
      "          [-5.5672e-01,  3.2762e-01, -1.1125e-02,  ...,  1.2215e+00,\n",
      "            3.4804e-01, -5.7436e-01],\n",
      "          [-2.5888e+00,  2.0766e+00,  7.1417e-01,  ..., -7.4109e-01,\n",
      "           -1.2020e+00,  1.1483e-01]],\n",
      "\n",
      "         [[ 5.6562e-01, -1.0266e+00,  1.7725e+00,  ..., -1.9673e-01,\n",
      "            4.9643e-01, -1.0458e+00],\n",
      "          [ 1.1523e+00, -6.2629e-01, -8.4997e-01,  ...,  9.3987e-01,\n",
      "           -1.4429e+00,  8.9150e-01],\n",
      "          [-2.7587e-01, -1.8783e+00,  6.1808e-01,  ..., -2.1713e-01,\n",
      "            2.7215e-01, -6.2241e-01],\n",
      "          ...,\n",
      "          [-8.1736e-01,  9.0916e-01, -2.5300e+00,  ...,  5.4461e-01,\n",
      "            9.6049e-01, -2.0339e-01],\n",
      "          [ 8.2046e-01,  3.2687e-01,  1.9697e+00,  ...,  7.5301e-01,\n",
      "            8.4826e-01,  2.8124e-01],\n",
      "          [ 2.6911e-01,  9.3671e-01,  9.8207e-01,  ..., -1.5827e-01,\n",
      "           -7.1130e-01, -5.3917e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.0723e-01,  2.0003e+00,  1.1601e-01,  ...,  1.0064e+00,\n",
      "           -1.1572e-01,  1.5252e-01],\n",
      "          [ 9.5191e-01,  1.6008e-02,  8.2259e-01,  ..., -9.5780e-01,\n",
      "            3.9349e-01, -1.0117e-02],\n",
      "          [-3.8666e-01,  3.9772e-01, -5.7618e-01,  ..., -1.5958e-01,\n",
      "           -6.0233e-01, -8.2620e-01],\n",
      "          ...,\n",
      "          [-1.1516e-01, -3.5638e-02,  1.0050e+00,  ..., -3.0251e-01,\n",
      "            6.7650e-01,  1.4441e+00],\n",
      "          [ 3.4209e-01, -8.4491e-01, -4.8162e-02,  ...,  7.9047e-01,\n",
      "            1.6211e+00, -1.9037e+00],\n",
      "          [ 1.1584e+00,  2.0542e-01,  8.6209e-01,  ..., -2.4908e-01,\n",
      "            7.5679e-01,  7.6751e-01]],\n",
      "\n",
      "         [[-5.0695e-01,  9.7947e-01, -2.1156e+00,  ...,  3.4819e-01,\n",
      "            7.3164e-01,  7.6352e-02],\n",
      "          [ 2.1191e+00,  9.8745e-01, -2.3272e-01,  ..., -1.4102e-01,\n",
      "            1.9811e-01, -9.3783e-01],\n",
      "          [ 2.8172e-01, -4.8819e-01,  1.4426e+00,  ...,  1.8091e+00,\n",
      "            5.5941e-01,  6.2325e-02],\n",
      "          ...,\n",
      "          [-2.4247e-01,  1.0823e+00,  7.7387e-01,  ..., -8.3022e-02,\n",
      "           -2.4161e-01,  6.3648e-01],\n",
      "          [ 8.6011e-01,  9.3569e-01,  5.8403e-01,  ..., -2.9391e-01,\n",
      "            1.3670e+00,  4.7872e-01],\n",
      "          [ 1.1914e+00, -3.8097e-01, -5.2423e-01,  ..., -1.0854e+00,\n",
      "           -8.3139e-01, -6.8752e-01]],\n",
      "\n",
      "         [[ 5.3712e-01,  5.5895e-01,  3.2141e-02,  ...,  1.3070e+00,\n",
      "            1.1026e+00, -2.2921e-01],\n",
      "          [ 2.6346e-01,  2.2159e+00, -6.2255e-01,  ...,  1.4321e-02,\n",
      "            1.0576e+00, -1.8366e+00],\n",
      "          [ 2.4063e+00,  7.1212e-01,  3.0372e-02,  ...,  2.3159e+00,\n",
      "           -1.8920e-01, -1.4193e+00],\n",
      "          ...,\n",
      "          [ 8.6388e-01, -7.6085e-01,  1.5347e+00,  ...,  5.6607e-01,\n",
      "            6.4474e-01,  1.0899e+00],\n",
      "          [-3.7233e-01, -1.4071e+00, -4.0108e-01,  ...,  1.1583e+00,\n",
      "            6.6370e-01, -1.3265e+00],\n",
      "          [-1.1679e-01,  1.5187e+00, -2.5510e-01,  ...,  1.9597e+00,\n",
      "           -9.6414e-01, -6.2694e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.7984e-01, -5.4502e-01, -1.6563e+00,  ..., -1.4292e+00,\n",
      "            3.9656e-01, -7.6656e-01],\n",
      "          [ 1.5943e+00, -1.4810e+00,  5.2609e-01,  ..., -5.7399e-01,\n",
      "           -2.3041e+00,  8.2293e-01],\n",
      "          [-2.3301e-01,  6.8010e-01, -1.0851e+00,  ..., -1.1538e+00,\n",
      "            2.2642e-01,  1.3222e-01],\n",
      "          ...,\n",
      "          [-2.6808e+00, -2.2243e+00, -1.6786e+00,  ..., -1.8456e+00,\n",
      "           -5.4728e-01, -1.1293e+00],\n",
      "          [ 7.4152e-01, -7.0841e-01, -1.0745e+00,  ..., -1.2002e+00,\n",
      "            5.5149e-01,  5.9136e-01],\n",
      "          [ 3.2476e-01, -1.8937e+00, -8.1652e-01,  ...,  5.5576e-01,\n",
      "            1.4972e+00,  1.0947e+00]],\n",
      "\n",
      "         [[ 2.1370e+00, -1.0619e+00,  9.3233e-01,  ...,  1.0374e+00,\n",
      "           -4.4120e-03, -1.1228e+00],\n",
      "          [ 5.5630e-01,  1.6765e-01,  2.2678e-01,  ...,  1.0338e+00,\n",
      "           -1.2566e+00, -1.7702e+00],\n",
      "          [-7.0937e-01,  2.4324e+00,  1.2251e+00,  ...,  1.1924e+00,\n",
      "            2.0524e+00,  3.3863e-01],\n",
      "          ...,\n",
      "          [ 1.1611e+00, -1.0431e+00,  3.9681e-01,  ..., -2.1942e+00,\n",
      "            1.0724e+00, -6.6668e-01],\n",
      "          [ 6.9855e-01, -5.4655e-01,  1.7129e+00,  ..., -2.3322e-01,\n",
      "           -2.3328e-01,  1.3876e+00],\n",
      "          [ 8.5214e-02,  1.7288e+00,  1.2721e-01,  ...,  2.5933e-01,\n",
      "            1.8970e-01, -1.2949e+00]],\n",
      "\n",
      "         [[-8.5263e-01,  4.8895e-01,  2.5508e+00,  ...,  3.1597e+00,\n",
      "           -1.3527e+00,  1.6891e+00],\n",
      "          [-1.1812e-01,  6.2487e-02,  4.9905e-01,  ...,  7.7473e-02,\n",
      "           -6.2721e-01,  1.2808e+00],\n",
      "          [ 4.5766e-01, -3.7843e-03, -1.2925e+00,  ...,  7.0476e-01,\n",
      "           -1.7713e+00, -7.3107e-01],\n",
      "          ...,\n",
      "          [ 1.0976e+00, -4.4672e-01, -7.1526e-01,  ..., -4.5590e-01,\n",
      "           -3.3443e-01,  4.9152e-02],\n",
      "          [ 1.9873e+00,  2.1680e-02,  1.2178e+00,  ..., -2.0382e+00,\n",
      "           -3.9185e-01, -1.0351e+00],\n",
      "          [ 1.6458e+00,  1.4011e+00, -7.3529e-01,  ...,  1.6875e+00,\n",
      "           -5.8154e-01, -2.1254e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.2661e-02,  2.5279e+00,  7.7776e-01,  ..., -1.2177e+00,\n",
      "            2.0861e+00, -3.0569e-01],\n",
      "          [-7.8488e-01, -9.3824e-01,  5.0350e-01,  ...,  9.8657e-01,\n",
      "            5.9476e-01, -1.7982e-01],\n",
      "          [-6.6242e-01, -1.4493e+00, -1.0082e-01,  ...,  9.1202e-01,\n",
      "            1.5916e+00, -3.5987e-01],\n",
      "          ...,\n",
      "          [-6.0099e-01, -1.2831e+00, -1.3008e+00,  ..., -1.9072e+00,\n",
      "            5.8911e-01,  1.0612e+00],\n",
      "          [ 7.2560e-01, -1.9421e+00, -9.3622e-01,  ...,  4.3085e-01,\n",
      "           -2.7550e+00, -1.5275e-01],\n",
      "          [-4.4284e-01, -3.7925e-01,  9.0451e-01,  ...,  1.6097e-01,\n",
      "           -4.2576e-01,  3.7882e-01]],\n",
      "\n",
      "         [[-3.1244e-01,  1.5615e+00,  6.6223e-01,  ...,  8.6901e-01,\n",
      "           -1.5057e-01,  1.6541e+00],\n",
      "          [ 1.0535e+00,  7.2254e-01, -8.4758e-02,  ..., -6.9714e-01,\n",
      "           -6.3001e-01, -1.0637e-01],\n",
      "          [-7.6892e-01, -2.6125e-02,  1.0301e+00,  ...,  6.7115e-01,\n",
      "           -3.0161e+00, -2.8100e-01],\n",
      "          ...,\n",
      "          [ 1.3146e+00,  2.4931e+00,  2.1530e-01,  ..., -1.6730e+00,\n",
      "            2.0233e+00,  7.4164e-01],\n",
      "          [ 4.5169e-01, -4.9813e-01, -5.6577e-02,  ..., -6.2951e-01,\n",
      "           -2.9647e-01, -3.5818e-01],\n",
      "          [-1.3377e+00, -1.1957e+00,  2.0696e-01,  ...,  3.1375e-01,\n",
      "           -5.3283e-03, -4.0367e-01]],\n",
      "\n",
      "         [[ 2.7605e-01, -1.5745e-01,  4.8957e-01,  ..., -7.1456e-01,\n",
      "            8.2485e-02,  7.0509e-01],\n",
      "          [-8.9238e-01, -6.8050e-01,  3.3510e-01,  ...,  1.4247e+00,\n",
      "           -7.0965e-01, -5.8775e-02],\n",
      "          [-6.2819e-02,  1.0718e+00, -1.0005e-01,  ..., -7.6358e-01,\n",
      "           -1.7745e-03, -1.2562e+00],\n",
      "          ...,\n",
      "          [-8.8217e-01,  4.6293e-01, -5.7073e-01,  ..., -1.5464e+00,\n",
      "           -2.5602e-01, -5.1204e-01],\n",
      "          [ 1.4496e+00, -8.3888e-01,  1.7255e+00,  ...,  3.7998e-01,\n",
      "           -5.1605e-03,  7.5143e-01],\n",
      "          [ 7.0789e-01,  1.1956e+00,  1.2894e+00,  ..., -1.3570e-01,\n",
      "           -2.5247e-01,  1.5657e+00]]],\n",
      "\n",
      "\n",
      "        [[[-3.3053e-01, -9.8382e-02, -2.0271e+00,  ...,  6.8312e-01,\n",
      "            8.5623e-01, -4.1527e-01],\n",
      "          [-1.0162e-01,  1.2581e+00, -1.0517e-01,  ...,  4.7373e-01,\n",
      "           -6.4034e-02, -6.1043e-01],\n",
      "          [-4.6718e-01, -1.1801e+00,  2.8487e-01,  ...,  3.4462e-01,\n",
      "           -1.0299e+00,  1.5068e+00],\n",
      "          ...,\n",
      "          [ 8.3130e-02, -6.1112e-01, -9.3601e-01,  ..., -6.9171e-01,\n",
      "           -1.2062e+00, -4.3318e-01],\n",
      "          [-5.5308e-01,  2.3898e+00,  4.5165e-01,  ...,  3.1993e-01,\n",
      "            6.3692e-01,  4.1639e-01],\n",
      "          [-3.2829e-01,  1.4491e+00,  9.6403e-01,  ...,  3.9991e-01,\n",
      "            1.7387e+00, -7.8327e-01]],\n",
      "\n",
      "         [[ 1.0880e+00,  6.2374e-01,  2.3780e-01,  ..., -8.7701e-01,\n",
      "           -8.6373e-01,  1.8450e+00],\n",
      "          [-1.7068e+00,  1.1275e-01, -1.0965e+00,  ..., -1.0129e+00,\n",
      "            3.1489e-01, -1.0585e+00],\n",
      "          [ 1.3972e+00,  5.3114e-01, -3.8551e-01,  ...,  5.0276e-01,\n",
      "           -4.6007e-01,  4.1892e-01],\n",
      "          ...,\n",
      "          [ 1.9031e+00, -5.7975e-01, -7.7806e-01,  ..., -1.3208e+00,\n",
      "            4.0466e-01,  4.7429e-01],\n",
      "          [ 2.2531e+00, -1.3244e-01,  8.1160e-01,  ..., -1.6538e-01,\n",
      "            4.6284e-01,  1.0636e+00],\n",
      "          [-1.2334e+00,  9.5296e-01, -9.2339e-01,  ..., -5.6101e-02,\n",
      "           -5.3348e-01, -1.7160e+00]],\n",
      "\n",
      "         [[-8.9956e-01, -3.8069e-01, -1.2358e+00,  ...,  5.9254e-01,\n",
      "            1.4590e+00,  5.9495e-01],\n",
      "          [-6.0043e-01,  2.7700e-01,  4.2707e-03,  ...,  1.3062e+00,\n",
      "            4.5119e-01, -6.6846e-01],\n",
      "          [-1.3567e+00,  3.2900e-01,  4.8788e-01,  ...,  1.7698e+00,\n",
      "            1.0209e-01,  5.8790e-01],\n",
      "          ...,\n",
      "          [ 1.0412e+00,  4.1140e-01,  6.4849e-02,  ..., -1.2288e+00,\n",
      "           -3.0649e-01,  2.4933e-02],\n",
      "          [-1.5594e+00, -1.6071e+00,  4.4284e-01,  ...,  3.0338e-01,\n",
      "            2.1343e+00,  3.7445e-01],\n",
      "          [-4.0116e-01,  8.7545e-01, -4.0846e-01,  ...,  2.0104e-02,\n",
      "            2.2124e+00,  1.1165e+00]]],\n",
      "\n",
      "\n",
      "        [[[-5.2869e-01, -2.3383e-01,  2.9707e-01,  ..., -1.5060e+00,\n",
      "           -1.6157e+00, -1.2576e+00],\n",
      "          [ 1.1213e+00, -2.8471e-03,  4.0681e-01,  ...,  5.0239e-01,\n",
      "            1.4218e+00,  3.3948e-01],\n",
      "          [ 1.0972e+00,  1.7206e-01, -1.1833e+00,  ..., -5.1202e-01,\n",
      "           -2.8330e-01,  1.4320e+00],\n",
      "          ...,\n",
      "          [ 7.7942e-01,  5.3002e-01, -2.0315e+00,  ...,  2.6592e-02,\n",
      "            9.8848e-01, -9.8789e-01],\n",
      "          [ 8.3798e-01,  1.0529e+00, -1.1669e+00,  ..., -7.6691e-02,\n",
      "            5.4262e-01,  3.4554e-01],\n",
      "          [-1.3276e+00,  2.0272e+00, -7.0290e-01,  ...,  2.3302e-01,\n",
      "           -1.6676e-02, -2.5621e-01]],\n",
      "\n",
      "         [[ 7.5456e-02,  1.0529e+00,  5.3150e-01,  ..., -1.5343e+00,\n",
      "           -1.9632e-01,  1.9900e-01],\n",
      "          [-6.7218e-02, -3.8223e-01, -1.1173e+00,  ..., -3.9972e-03,\n",
      "            9.4278e-01,  2.7103e-02],\n",
      "          [ 8.3582e-01,  6.2717e-01,  2.4510e-01,  ..., -4.6211e-01,\n",
      "           -1.3207e+00, -1.3086e+00],\n",
      "          ...,\n",
      "          [-5.5825e-01,  1.6412e-01, -5.2276e-01,  ..., -3.1847e-01,\n",
      "            3.8284e-01,  1.0580e+00],\n",
      "          [-6.6989e-01,  8.7206e-01,  2.1772e-01,  ..., -1.0171e+00,\n",
      "            1.2961e+00,  4.6808e-01],\n",
      "          [-8.1194e-02,  1.1017e+00, -1.3442e-01,  ...,  1.2686e+00,\n",
      "            8.0917e-01, -1.1356e-01]],\n",
      "\n",
      "         [[ 3.6867e-01, -2.7736e-02, -2.3128e-01,  ..., -1.7252e-01,\n",
      "            5.6924e-01,  1.9496e+00],\n",
      "          [-6.9547e-01,  8.5043e-01,  9.1825e-01,  ...,  2.1718e+00,\n",
      "            4.8583e-01,  1.6204e+00],\n",
      "          [-8.5268e-01, -8.5158e-01,  7.1388e-01,  ...,  1.3856e+00,\n",
      "            7.6031e-01, -1.3406e+00],\n",
      "          ...,\n",
      "          [ 1.0614e+00, -9.9981e-01,  8.9805e-01,  ...,  8.1634e-01,\n",
      "           -5.9414e-01,  5.8846e-01],\n",
      "          [-4.2297e-01,  6.1302e-01, -5.8139e-01,  ..., -2.0702e+00,\n",
      "           -2.1238e-01, -1.2633e+00],\n",
      "          [-2.5555e-01,  1.1567e-01, -9.8029e-01,  ..., -5.1717e-01,\n",
      "            2.6528e+00, -2.4323e-01]]]])\n",
      "torch.Size([10000, 3, 28, 28])\n",
      "torch.Size([10000, 3, 784])\n",
      "torch.Size([10000, 3, 784])\n"
     ]
    }
   ],
   "source": [
    "# \"MNIST\"\n",
    "# torch.rand 返回一个张量，包含了从区间[0, 1)的均匀分布中抽取的一组随机数\n",
    "# torch.randn 返回一个张量，包含了从标准正态分布（均值为0，方差为1，即高斯白噪声）中抽取的一组随机数。张量的形状由参数sizes定义。\n",
    "\n",
    "N, C, W, H = 10000, 3, 28, 28\n",
    "X = torch.randn((N, C, W, H))\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(X.view(N, C, 784).shape)\n",
    "print(X.view(-1, C, 784).shape) # 这里-1与reshape（-1，x）类似 automatically choose the 0th dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXgxfCTMOjIp"
   },
   "source": [
    "### BROADCASTING SEMANTICS\n",
    "Two tensors are “broadcastable” if the following rules hold:\n",
    "\n",
    "Each tensor has at least one dimension.\n",
    "\n",
    "When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9ioj-DAhOjiN",
    "outputId": "53f3e777-491b-4be6-a6a2-9eedc70f2046"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0194e-38],\n",
      "          [9.1837e-39],\n",
      "          [4.6837e-39],\n",
      "          [9.2755e-39]]],\n",
      "\n",
      "\n",
      "        [[[1.0837e-38],\n",
      "          [8.4490e-39],\n",
      "          [1.0653e-38],\n",
      "          [9.1837e-39]]],\n",
      "\n",
      "\n",
      "        [[[8.4490e-39],\n",
      "          [9.6429e-39],\n",
      "          [8.4490e-39],\n",
      "          [1.0745e-38]]],\n",
      "\n",
      "\n",
      "        [[[1.0653e-38],\n",
      "          [1.0286e-38],\n",
      "          [1.0194e-38],\n",
      "          [9.2755e-39]]],\n",
      "\n",
      "\n",
      "        [[[1.0561e-38],\n",
      "          [1.0102e-38],\n",
      "          [8.4490e-39],\n",
      "          [1.0745e-38]]]])\n",
      "torch.Size([5, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch operations support NumPy Broadcasting Semantics.\n",
    "x=torch.empty(5,1,4,1)\n",
    "y=torch.empty(  3,1,1) \n",
    "print(x)\n",
    "# 相加时 已大的为主\n",
    "print((x+y).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3vQ3yD9MThP"
   },
   "source": [
    "## Computation graphs\n",
    "\n",
    "What's special about PyTorch's `tensor` object is that it implicitly creates a computation graph in the background. A computation graph is a a way of writing a mathematical expression as a graph. There is an algorithm to compute the gradients of all the variables of a computation graph in time on the same order it is to compute the function itself.\n",
    "\n",
    "Consider the expression $e=(a+b)*(b+1)$ with values $a=2, b=1$. We can draw the evaluated computation graph as\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "In PyTorch, we can write this as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-HpojJ_MThQ"
   },
   "source": [
    "![tree-img](https://colah.github.io/posts/2015-08-Backprop/img/tree-eval.png)\n",
    "\n",
    "[source](https://colah.github.io/posts/2015-08-Backprop/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "n7NGX7CVMThR",
    "outputId": "e390ff56-83dc-458d-ca87-e1d57b9304af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c tensor(3., grad_fn=<AddBackward0>)\n",
      "d tensor(2., grad_fn=<AddBackward0>)\n",
      "e tensor(6., grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(2.0, requires_grad=True) # we set requires_grad=True to let PyTorch know to keep the graph\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "c = a + b\n",
    "d = b + 1\n",
    "e = c * d\n",
    "print('c', c)\n",
    "print('d', d)\n",
    "print('e', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orGtJTjkMThU"
   },
   "source": [
    "We can see that PyTorch kept track of the computation graph for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPZfJ1hy4uxj"
   },
   "source": [
    "## CUDA SEMANTICS\n",
    "It's easy cupy tensor from cpu to gpu or from gpu to cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "JYqe5vVv43tG",
    "outputId": "202de93f-1f82-4ee4-9c53-0ec985655323",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
      "        0.1897])\n",
      "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
      "        0.1897], device='cuda:0')\n",
      "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
      "        0.1897])\n"
     ]
    }
   ],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "gpu = torch.device(\"cuda\")\n",
    "\n",
    "x = torch.rand(10)\n",
    "print(x)\n",
    "x = x.to(gpu)\n",
    "print(x)\n",
    "x = x.to(cpu)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7Wy2mEOMThU"
   },
   "source": [
    "## PyTorch as an auto grad framework\n",
    "\n",
    "Now that we have seen that PyTorch keeps the graph around for us, let's use it to compute some gradients for us.\n",
    "\n",
    "Consider the function $f(x) = (x-2)^2$.\n",
    "\n",
    "Q: Compute $\\frac{d}{dx} f(x)$ and then compute $f'(1)$.\n",
    "\n",
    "We make a `backward()` call on the leaf variable (`y`) in the computation, computing all the gradients of `y` at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "zvN0jSOKMThV",
    "outputId": "c5b113bc-1b6b-42d7-83a1-fdfe6240a2da",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical f'(x): tensor([-2.], grad_fn=<MulBackward0>)\n",
      "PyTorch's f'(x): tensor([-2.])\n"
     ]
    }
   ],
   "source": [
    "# 比较手工求导 与 Pytorch求导\n",
    "\n",
    "# 原函数\n",
    "def f(x):\n",
    "    return (x-2)**2\n",
    "\n",
    "# 导函数\n",
    "def fp(x):\n",
    "    return 2*(x-2)\n",
    "\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "y = f(x)\n",
    "y.backward() # 反向求导，结果会赋值给x.grad\n",
    "\n",
    "# 比较\n",
    "print('Analytical f\\'(x):', fp(x))\n",
    "print('PyTorch\\'s f\\'(x):', x.grad)  # y.backward()之后，x.grad才会有值\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvJR6H7KMThX"
   },
   "source": [
    "It can also find gradients of functions.\n",
    "\n",
    "Let $w = [w_1, w_2]^T$\n",
    "\n",
    "Consider $g(w) = 2w_1w_2 + w_2\\cos(w_1)$\n",
    "\n",
    "Q: Compute $\\nabla_w g(w)$ and verify $\\nabla_w g([\\pi,1]) = [2, \\pi - 1]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "-WCp53C1MThY",
    "outputId": "2d448c41-cb28-46c1-e072-5095a1dd82aa",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical grad g(w) tensor([2.0000, 5.2832])\n",
      "PyTorch's grad g(w) tensor([2.0000, 5.2832])\n"
     ]
    }
   ],
   "source": [
    "def g(w):\n",
    "    return 2*w[0]*w[1] + w[1]*torch.cos(w[0])\n",
    "\n",
    "def grad_g(w):\n",
    "    return torch.tensor([2*w[1] - w[1]*torch.sin(w[0]), 2*w[0] + torch.cos(w[0])])\n",
    "\n",
    "w = torch.tensor([np.pi, 1], requires_grad=True)\n",
    "\n",
    "z = g(w)\n",
    "z.backward()\n",
    "\n",
    "print('Analytical grad g(w)', grad_g(w))\n",
    "print('PyTorch\\'s grad g(w)', w.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqyBFdobMTha"
   },
   "source": [
    "## Using the gradients\n",
    "Now that we have gradients, we can use our favorite optimization algorithm: gradient descent!\n",
    "\n",
    "Let $f$ the same function we defined above.\n",
    "\n",
    "Q: What is the value of $x$ that minimizes $f$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "m4-8fhqAMThb",
    "outputId": "98f1d676-b28f-4269-8cd0-17a405d9a8f8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tx,\tf(x),\tf'(x),\tf'(x) pytorch\n",
      "0,\t5.000,\t9.000,\t6.000,\t6.000\n",
      "1,\t3.500,\t2.250,\t3.000,\t3.000\n",
      "2,\t2.750,\t0.562,\t1.500,\t1.500\n",
      "3,\t2.375,\t0.141,\t0.750,\t0.750\n",
      "4,\t2.188,\t0.035,\t0.375,\t0.375\n",
      "5,\t2.094,\t0.009,\t0.188,\t0.188\n",
      "6,\t2.047,\t0.002,\t0.094,\t0.094\n",
      "7,\t2.023,\t0.001,\t0.047,\t0.047\n",
      "8,\t2.012,\t0.000,\t0.023,\t0.023\n",
      "9,\t2.006,\t0.000,\t0.012,\t0.012\n",
      "10,\t2.003,\t0.000,\t0.006,\t0.006\n",
      "11,\t2.001,\t0.000,\t0.003,\t0.003\n",
      "12,\t2.001,\t0.000,\t0.001,\t0.001\n",
      "13,\t2.000,\t0.000,\t0.001,\t0.001\n",
      "14,\t2.000,\t0.000,\t0.000,\t0.000\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.0], requires_grad=True)\n",
    "step_size = 0.25\n",
    "\n",
    "print('iter,\\tx,\\tf(x),\\tf\\'(x),\\tf\\'(x) pytorch')\n",
    "for i in range(15):\n",
    "    y = f(x)\n",
    "    y.backward() # compute the gradient\n",
    "    \n",
    "    print('{},\\t{:.3f},\\t{:.3f},\\t{:.3f},\\t{:.3f}'.format(i, x.item(), f(x).item(), fp(x).item(), x.grad.item()))\n",
    "    \n",
    "    x.data = x.data - step_size * x.grad # perform a GD update step\n",
    "    \n",
    "    # We need to zero the grad variable since the backward()\n",
    "    # call accumulates the gradients in .grad instead of overwriting.\n",
    "    # The detach_() is for efficiency. You do not need to worry too much about it.\n",
    "    x.grad.detach_()\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TPWiwARMThd"
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "Now, instead of minimizing a made-up function, lets minimize a loss function on some made-up data.\n",
    "\n",
    "We will implement Gradient Descent in order to solve the task of linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "3el-4esEMThe",
    "outputId": "40f1a3ea-24e9-4fd1-b93d-12882e6052c7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape torch.Size([50, 2])\n",
      "y shape torch.Size([50, 1])\n",
      "w shape torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# make a simple linear dataset with some noise\n",
    "\n",
    "d = 2\n",
    "n = 50\n",
    "X = torch.randn(n,d)\n",
    "true_w = torch.tensor([[-1.0], [2.0]])\n",
    "y = X @ true_w + torch.randn(n,1) * 0.1 # y=x*w(训练参数)+噪声\n",
    "print('X shape', X.shape)\n",
    "print('y shape', y.shape)\n",
    "print('w shape', true_w.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlzoXa6UMThg"
   },
   "source": [
    "### Note: dimensions\n",
    "PyTorch does a lot of operations on batches of data. The convention is to have your data be of size $(N, d)$ where $N$ is the size of the batch of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l08nQdE9MThp"
   },
   "source": [
    "### Sanity check\n",
    "To verify PyTorch is computing the gradients correctly, let's recall the gradient for the RSS objective:\n",
    "\n",
    "$$\\nabla_w \\mathcal{L}_{RSS}(w; X) = \\nabla_w\\frac{1}{n} ||y - Xw||_2^2 = -\\frac{2}{n}X^T(y-Xw)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "R5HfA5YcMThp",
    "outputId": "cad02754-6dde-4c34-c4dc-b273bcf2e614",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient [ 4.342543  -3.5023162]\n",
      "PyTorch's gradient [ 4.342543 -3.502316]\n"
     ]
    }
   ],
   "source": [
    "# define a linear model with no bias\n",
    "def model(X, w):\n",
    "    return X @ w\n",
    "\n",
    "# the residual sum of squares loss function\n",
    "def rss(y, y_hat):\n",
    "    return torch.norm(y - y_hat)**2 / n\n",
    "\n",
    "# analytical expression for the gradient\n",
    "def grad_rss(X, y, w):\n",
    "    return -2*X.t() @ (y - X @ w) / n\n",
    "\n",
    "w = torch.tensor([[1.], [0]], requires_grad=True)\n",
    "y_hat = model(X, w)\n",
    "\n",
    "loss = rss(y, y_hat)\n",
    "loss.backward()\n",
    "\n",
    "print('Analytical gradient', grad_rss(X, y, w).detach().view(2).numpy())\n",
    "print('PyTorch\\'s gradient', w.grad.view(2).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tmg4eFQAMThr"
   },
   "source": [
    "Now that we've seen PyTorch is doing the right think, let's use the gradients!\n",
    "\n",
    "## Linear regression using GD with automatically computed derivatives\n",
    "\n",
    "We will now use the gradients to run the gradient descent algorithm.\n",
    "\n",
    "Note: This example is an illustration to connect ideas we have seen before to PyTorch's way of doing things. We will see how to do this in the \"PyTorchic\" way in the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "gea4LETnMThs",
    "outputId": "e9701f26-7f06-4bc2-80c2-1cb2b68ea666",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0,\t7.82,\t[0.13149136 0.70046324]\n",
      "1,\t2.84,\t[-0.11822014  0.9229876 ]\n",
      "2,\t1.84,\t[-0.31444427  1.1054724 ]\n",
      "3,\t1.19,\t[-0.4684834  1.2552956]\n",
      "4,\t0.77,\t[-0.58927345  1.3784461 ]\n",
      "5,\t0.50,\t[-0.68387645  1.4797904 ]\n",
      "6,\t0.33,\t[-0.75787055  1.563287  ]\n",
      "7,\t0.22,\t[-0.8156596  1.632159 ]\n",
      "8,\t0.15,\t[-0.86071837  1.6890337 ]\n",
      "9,\t0.10,\t[-0.89578694  1.736055  ]\n",
      "10,\t0.07,\t[-0.9230244  1.7749742]\n",
      "11,\t0.05,\t[-0.94413096  1.8072236 ]\n",
      "12,\t0.03,\t[-0.9604442  1.8339758]\n",
      "13,\t0.02,\t[-0.9730157  1.8561921]\n",
      "14,\t0.02,\t[-0.9826713  1.8746614]\n",
      "15,\t0.01,\t[-0.99005884  1.8900318 ]\n",
      "16,\t0.01,\t[-0.99568594  1.9028363 ]\n",
      "17,\t0.01,\t[-0.99994993  1.913514  ]\n",
      "18,\t0.01,\t[-1.0031612  1.9224268]\n",
      "19,\t0.01,\t[-1.0055621  1.9298735]\n",
      "\n",
      "true w\t\t [-1.  2.]\n",
      "estimated w\t [-1.0055621  1.9298735]\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.1\n",
    "\n",
    "print('iter,\\tloss,\\tw')\n",
    "for i in range(20):\n",
    "    y_hat = model(X, w)\n",
    "    loss = rss(y, y_hat)\n",
    "    \n",
    "    loss.backward() # compute the gradient of the loss\n",
    "    \n",
    "    w.data = w.data - step_size * w.grad # do a gradient descent step\n",
    "    \n",
    "    print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), w.view(2).detach().numpy()))\n",
    "    \n",
    "    # We need to zero the grad variable since the backward()\n",
    "    # call accumulates the gradients in .grad instead of overwriting.\n",
    "    # The detach_() is for efficiency. You do not need to worry too much about it.\n",
    "    w.grad.detach()\n",
    "    w.grad.zero_()\n",
    "\n",
    "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', w.view(2).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AexdjJtcMThu"
   },
   "source": [
    "## torch.nn.Module\n",
    "\n",
    "`Module` is PyTorch's way of performing operations on tensors. Modules are implemented as subclasses of the `torch.nn.Module` class. All modules are callable and can be composed together to create complex functions.\n",
    "\n",
    "[`torch.nn` docs](https://pytorch.org/docs/stable/nn.html)\n",
    "\n",
    "Note: most of the functionality implemented for modules can be accessed in a functional form via `torch.nn.functional`, but these require you to create and manage the weight tensors yourself.\n",
    "\n",
    "[`torch.nn.functional` docs](https://pytorch.org/docs/stable/nn.html#torch-nn-functional)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuigjBAiMThv"
   },
   "source": [
    "### Linear Module\n",
    "The bread and butter of modules is the Linear module which does a linear transformation with a bias. It takes the input and output dimensions as parameters, and creates the weights in the object.\n",
    "\n",
    "Unlike how we initialized our $w$ manually, the Linear module automatically initializes the weights randomly. For minimizing non convex loss functions (e.g. training neural networks), initialization is important and can affect results. If training isn't working as well as expected, one thing to try is manually initializing the weights to something different from the default. PyTorch implements some common initializations in `torch.nn.init`.\n",
    "\n",
    "[`torch.nn.init` docs](https://pytorch.org/docs/stable/nn.html#torch-nn-init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "Yi4lhPVCMThv",
    "outputId": "e0b12ab0-9759-460e-bd50-07cdb0003ae5",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_tensor.shape torch.Size([2, 3])\n",
      "linear_module.shape torch.Size([4, 3])\n",
      "transformed.shape torch.Size([2, 4])\n",
      "\n",
      "transformed:\n",
      " tensor([[1.7471, 1.8767, 1.0113, 0.2725],\n",
      "        [4.5368, 4.9384, 1.6543, 0.4972]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "recovery:\n",
      " tensor([[1.7471, 1.8767, 1.0113, 0.2725],\n",
      "        [4.5368, 4.9384, 1.6543, 0.4972]], grad_fn=<AddBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 样本为2个3维度特征的向量 A_2x3\n",
    "example_tensor = torch.tensor([[1.,2,3], [4,5,6]])\n",
    "# 欲变为4维度特征 即把A_2x3 变为 C_2x4 , 因C_2x4 = A_2x3 * B_3x4 + Bias，所以需要一个B_3x4, \n",
    "# nn.Linear 会帮你完成转换， 转换过程中会得到这个B_3x4以及Bias，也就是下面的linear_module.weight 和 linear_module.bias\n",
    "d_in = 3\n",
    "d_out = 4\n",
    "linear_module = nn.Linear(d_in, d_out) # d_in输入维度 d_out输出维度\n",
    "\n",
    "# 转换\n",
    "transformed = linear_module(example_tensor)\n",
    "\n",
    "print('example_tensor.shape', example_tensor.shape)\n",
    "\n",
    "# 这里linear_module.weight 不是3x4，是因为运算中使用了转置，4x3会转成3x4\n",
    "print('linear_module.shape', linear_module.weight.shape)\n",
    "print('transformed.shape', transformed.shape)\n",
    "# print()\n",
    "# print('We can see that the weights exist in the background')\n",
    "# print('W:', linear_module.weight)\n",
    "# print('b:', linear_module.bias)\n",
    "# print()\n",
    "print()\n",
    "print('transformed:\\n',transformed)\n",
    "print()\n",
    "print('recovery:\\n',example_tensor @ linear_module.weight.T + linear_module.bias)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLNmKz9BMThx"
   },
   "source": [
    "### Activation functions\n",
    "PyTorch implements a number of activation functions including but not limited to `ReLU`, `Tanh`, and `Sigmoid`. Since they are modules, they need to be instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "toOsF9qXMThy",
    "outputId": "47865021-7a3f-4f36-8151-29d5cb41e382",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_tensor tensor([-1.,  1.,  0.])\n",
      "activated tensor([0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 激活函数\n",
    "activation_fn = nn.ReLU() # we instantiate an instance of the ReLU module\n",
    "example_tensor = torch.tensor([-1.0, 1.0, 0.0])\n",
    "activated = activation_fn(example_tensor)\n",
    "print('example_tensor', example_tensor)\n",
    "print('activated', activated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPdu_KS_MTh0"
   },
   "source": [
    "### Sequential\n",
    "\n",
    "Many times, we want to compose Modules together. `torch.nn.Sequential` provides a good interface for composing simple modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yn-jaKd3MTh1",
    "outputId": "1dd86d16-7560-4882-c7bf-c8b3f1e63fbd",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 模块序列化：model(x),x会经过下面构建model的4个module\n",
    "d_in = 3\n",
    "d_hidden = 4\n",
    "d_out = 1\n",
    "model = torch.nn.Sequential(\n",
    "                            nn.Linear(d_in, d_hidden),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(d_hidden, d_out),\n",
    "                            nn.Sigmoid()\n",
    "                           )\n",
    "\n",
    "example_tensor = torch.tensor([[1.,2,3],[4,5,6]])\n",
    "transformed = model(example_tensor)\n",
    "print('transformed', transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5GkJ1UTMTh2"
   },
   "source": [
    "Note: we can access *all* of the parameters (of any `nn.Module`) with the `parameters()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "zTTsMkxoMTh3",
    "outputId": "6b52d368-18a1-4486-8735-00d82482dc2b",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3128,  0.2707, -0.3952],\n",
      "        [ 0.1285,  0.1777, -0.4675],\n",
      "        [ 0.0452, -0.5630, -0.1999],\n",
      "        [ 0.5431,  0.0524,  0.1126]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2683, -0.2361,  0.2769, -0.1380], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4902, -0.0928, -0.2907,  0.0734]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0394], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 拿到上面4个module的参数\n",
    "params = model.parameters()\n",
    "for param in params:\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jifMOIcNMTh5"
   },
   "source": [
    "### Loss functions\n",
    "PyTorch implements many common loss functions including `MSELoss` and `CrossEntropyLoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "b8NXNEhlMTh6",
    "outputId": "24e9a149-87e7-48a4-f96f-1ee6a14f0f86",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667)\n"
     ]
    }
   ],
   "source": [
    "mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "\n",
    "input = torch.tensor([[0., 0, 0]])\n",
    "target = torch.tensor([[1., 0, -1]])\n",
    "\n",
    "loss = mse_loss_fn(input, target)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hh0YZh1QMTh7"
   },
   "source": [
    "## torch.optim\n",
    "PyTorch implements a number of gradient-based optimization methods in `torch.optim`, including Gradient Descent. At the minimum, it takes in the model parameters and a learning rate.\n",
    "\n",
    "Optimizers do not compute the gradients for you, so you must call `backward()` yourself. You also must call the `optim.zero_grad()` function before calling `backward()` since by default PyTorch does and inplace add to the `.grad` member variable rather than overwriting it.\n",
    "\n",
    "This does both the `detach_()` and `zero_()` calls on all tensor's `grad` variables.\n",
    "\n",
    "[`torch.optim` docs](https://pytorch.org/docs/stable/optim.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "CldNJzMHMTh8",
    "outputId": "c62667a6-2b2a-4191-85d2-84e3ba51f1be",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params before: Parameter containing:\n",
      "tensor([[-0.4950]], requires_grad=True)\n",
      "model params after: Parameter containing:\n",
      "tensor([[-0.4427]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# create a simple model\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# create a simple dataset\n",
    "X_simple = torch.tensor([[1.]])\n",
    "y_simple = torch.tensor([[2.]])\n",
    "\n",
    "# create our optimizer\n",
    "# 这里SGD （学习率的一种更新策略 sgd/momentum/Nesterov/adagrad/adadelta）\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "y_hat = model(X_simple)\n",
    "print('model params before:', model.weight)\n",
    "loss = mse_loss_fn(y_hat, y_simple)\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "print('model params after:', model.weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxv9VHTOMTh-"
   },
   "source": [
    "As we can see, the parameter was updated in the correct direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjiD9FATMTh_"
   },
   "source": [
    "## Linear regression using GD with automatically computed derivatives and PyTorch's Modules\n",
    "\n",
    "Now let's combine what we've learned to solve linear regression in a \"PyTorchic\" way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "RGz8gPweMTh_",
    "outputId": "e3401d7e-9f8a-4e42-96e5-dfb00c32ccf6",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0,\t2.99,\t[-0.5453574  0.5141269]\n",
      "1,\t2.02,\t[-0.666086   0.7522292]\n",
      "2,\t1.37,\t[-0.75831056  0.9504566 ]\n",
      "3,\t0.94,\t[-0.82842976  1.1156547 ]\n",
      "4,\t0.64,\t[-0.8814486  1.2534635]\n",
      "5,\t0.44,\t[-0.92127615  1.3685349 ]\n",
      "6,\t0.31,\t[-0.9509604  1.4647106]\n",
      "7,\t0.22,\t[-0.9728737  1.5451664]\n",
      "8,\t0.15,\t[-0.98885876  1.6125307 ]\n",
      "9,\t0.11,\t[-1.0003437  1.6689818]\n",
      "10,\t0.08,\t[-1.0084321  1.7163262]\n",
      "11,\t0.06,\t[-1.0139749  1.7560644]\n",
      "12,\t0.04,\t[-1.0176253  1.7894436]\n",
      "13,\t0.03,\t[-1.0198835  1.8175017]\n",
      "14,\t0.02,\t[-1.0211303  1.8411033]\n",
      "15,\t0.02,\t[-1.0216544  1.8609697]\n",
      "16,\t0.02,\t[-1.0216731  1.8777025]\n",
      "17,\t0.01,\t[-1.0213491  1.8918046]\n",
      "18,\t0.01,\t[-1.020803   1.9036964]\n",
      "19,\t0.01,\t[-1.020123   1.9137299]\n",
      "\n",
      "true w\t\t [-1.  2.]\n",
      "estimated w\t [-1.020123   1.9137299]\n"
     ]
    }
   ],
   "source": [
    "# 一个使用pytorch实现的梯度下降\n",
    "\n",
    "step_size = 0.1\n",
    "\n",
    "# 模型fun\n",
    "linear_module = nn.Linear(d, 1, bias=False)\n",
    "# 损失函数\n",
    "loss_func = nn.MSELoss()\n",
    "# 学习率优化策略\n",
    "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\n",
    "\n",
    "print('iter,\\tloss,\\tw')\n",
    "\n",
    "for i in range(20):\n",
    "    y_hat = linear_module(X) # 计算预测值\n",
    "    loss = loss_func(y_hat, y) # 计算loss\n",
    "    optim.zero_grad() # 清除上次计算的梯度dw\n",
    "    \n",
    "    # 计算梯度 loss fun中w的导数，w就是linear_module.parameters()\n",
    "    # loss是怎么得到w的，推测 loss <- loss_func <- y_hat <- linear_module \n",
    "    # loss算出梯度dw，保存到linear_module\n",
    "    loss.backward() \n",
    "    \n",
    "    #optim 持有 linear_module，即也拥有上面计算出的dw，最后用策略更新w\n",
    "    optim.step()\n",
    "    \n",
    "    print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(2).detach().numpy()))\n",
    "\n",
    "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3j9hUvjQMTiD"
   },
   "source": [
    "## Linear regression using SGD \n",
    "In the previous examples, we computed the average gradient over the entire dataset (Gradient Descent). We can implement Stochastic Gradient Descent with a simple modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "q3EUcFMbMTiE",
    "outputId": "34a3f055-cefa-4bc2-b6fb-13b3117b620c",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0,\t4.46,\t[-0.20530997  0.66900945]\n",
      "20,\t1.28,\t[-0.34921718  0.8908058 ]\n",
      "40,\t0.73,\t[-0.513422   1.1883926]\n",
      "60,\t0.51,\t[-0.6704745  1.5351907]\n",
      "80,\t0.16,\t[-0.7813061  1.6464837]\n",
      "100,\t0.20,\t[-0.8568147  1.7569876]\n",
      "120,\t0.03,\t[-0.90830195  1.8347709 ]\n",
      "140,\t0.00,\t[-0.9449066  1.888105 ]\n",
      "160,\t0.00,\t[-0.96574944  1.9163204 ]\n",
      "180,\t0.01,\t[-0.98202056  1.9221277 ]\n",
      "\n",
      "true w\t\t [-1.  2.]\n",
      "estimated w\t [-0.98299205  1.9443793 ]\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.01\n",
    "\n",
    "linear_module = nn.Linear(d, 1)\n",
    "loss_func = nn.MSELoss()\n",
    "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\n",
    "print('iter,\\tloss,\\tw')\n",
    "for i in range(200):\n",
    "    # 分批喂 从样本集中随机取n个样本\n",
    "    rand_idx = np.random.choice(n) # take a random point from the dataset\n",
    "    x = X[rand_idx] \n",
    "    y_hat = linear_module(x)\n",
    "    loss = loss_func(y_hat, y[rand_idx]) # only compute the loss on the single point\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print('{},\\t{:.2f},\\t{}'.format(i, loss.item(), linear_module.weight.view(2).detach().numpy()))\n",
    "\n",
    "print('\\ntrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Re8u8STMTiI"
   },
   "source": [
    "# Neural Network Basics in PyTorch\n",
    "We will try and fit a simple neural network to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "401On5ckMTiJ",
    "outputId": "8f604a99-f52f-4736-fc9c-4de39d01c96d",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "d = 1\n",
    "n = 200\n",
    "# 样本集\n",
    "X = torch.rand(n,d)\n",
    "# 真实值\n",
    "y = 4 * torch.sin(np.pi * X) * torch.cos(6*np.pi*X**2)\n",
    "\n",
    "plt.scatter(X.numpy(), y.numpy())\n",
    "plt.title('plot of $f(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQl2A_XDMTiL"
   },
   "source": [
    "Here we define a simple two hidden layer neural network with Tanh activations. There are a few hyper parameters to play with to get a feel for how they change the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "C72y6DtpMTiM",
    "outputId": "e91ae971-a87f-430e-ab35-1918173b0b4f",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss\n",
      "0,\t3.99\n",
      "600,\t3.70\n",
      "1200,\t2.45\n",
      "1800,\t1.13\n",
      "2400,\t0.88\n",
      "3000,\t0.63\n",
      "3600,\t0.27\n",
      "4200,\t0.08\n",
      "4800,\t0.08\n",
      "5400,\t0.06\n"
     ]
    }
   ],
   "source": [
    "# feel free to play with these parameters\n",
    "\n",
    "step_size = 0.05\n",
    "n_epochs = 6000\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 32\n",
    "d_out = 1\n",
    "\n",
    "neural_network = nn.Sequential(\n",
    "                            nn.Linear(d, n_hidden_1), \n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(n_hidden_1, n_hidden_2),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(n_hidden_2, d_out)\n",
    "                            )\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "optim = torch.optim.SGD(neural_network.parameters(), lr=step_size)\n",
    "print('iter,\\tloss')\n",
    "for i in range(n_epochs):\n",
    "    y_hat = neural_network(X)\n",
    "    loss = loss_func(y_hat, y)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if i % (n_epochs // 10) == 0:\n",
    "        print('{},\\t{:.2f}'.format(i, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "vQBkFt9LMTiO",
    "outputId": "c4353831-4f51-4087-fcaf-41b21cca1b73",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 从[0,1]内取等间隔的50个数  按第二维维数d，来形成第一维维数\n",
    "X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\n",
    "# 预测y_hat(neural_network 上面cell已训练好)\n",
    "y_hat = neural_network(X_grid)\n",
    "plt.scatter(X.numpy(), y.numpy())\n",
    "plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\n",
    "plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8mPkng3MTiQ"
   },
   "source": [
    "# Things that might help on the homework\n",
    "\n",
    "## Brief Sidenote: Momentum\n",
    "\n",
    "There are other optimization algorithms besides stochastic gradient descent. One is a modification of SGD called momentum. We won't get into it here, but if you would like to read more [here](https://distill.pub/2017/momentum/) is a good place to start.\n",
    "\n",
    "We only change the step size and add the momentum keyword argument to the optimizer. Notice how it reduces the training loss in fewer iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "QhGP8gZDMTiQ",
    "outputId": "41f87ecd-db93-46d8-9798-30795069e265",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss\n",
      "0,\t3.98\n",
      "150,\t2.77\n",
      "300,\t0.84\n",
      "450,\t0.26\n",
      "600,\t0.06\n",
      "750,\t0.04\n",
      "900,\t0.01\n",
      "1050,\t0.00\n",
      "1200,\t0.00\n",
      "1350,\t0.00\n"
     ]
    }
   ],
   "source": [
    "# 在上面那个cell的基础上\n",
    "# 使用momentum加快收敛速度\n",
    "\n",
    "# feel free to play with these parameters\n",
    "\n",
    "step_size = 0.05\n",
    "momentum = 0.9\n",
    "n_epochs = 1500\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 32\n",
    "d_out = 1\n",
    "\n",
    "neural_network = nn.Sequential(\n",
    "                            nn.Linear(d, n_hidden_1), \n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(n_hidden_1, n_hidden_2),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(n_hidden_2, d_out)\n",
    "                            )\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "optim = torch.optim.SGD(neural_network.parameters(), lr=step_size, momentum=momentum)\n",
    "print('iter,\\tloss')\n",
    "for i in range(n_epochs):\n",
    "    y_hat = neural_network(X)\n",
    "    loss = loss_func(y_hat, y)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if i % (n_epochs // 10) == 0:\n",
    "        print('{},\\t{:.2f}'.format(i, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "rGZL4mkbMTiS",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\n",
    "y_hat = neural_network(X_grid)\n",
    "plt.scatter(X.numpy(), y.numpy())\n",
    "plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\n",
    "plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSO1McZLMTiT"
   },
   "source": [
    "## CrossEntropyLoss\n",
    "So far, we have been considering regression tasks and have used the [MSELoss](https://pytorch.org/docs/stable/nn.html#torch.nn.MSELoss) module. For the homework, we will be performing a classification task and will use the cross entropy loss.\n",
    "\n",
    "PyTorch implements a version of the cross entropy loss in one module called [CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss). Its usage is slightly different than MSE, so we will break it down here. \n",
    "\n",
    "- input: The first parameter to CrossEntropyLoss is the output of our network. It expects a *real valued* tensor of dimensions $(N,C)$ where $N$ is the minibatch size and $C$ is the number of classes. In our case $N=3$ and $C=2$. The values along the second dimension correspond to raw unnormalized scores for each class. The CrossEntropyLoss module does the softmax calculation for us, so we do not need to apply our own softmax to the output of our neural network.\n",
    "- output: The second parameter to CrossEntropyLoss is the true label. It expects an *integer valued* tensor of dimension $(N)$. The integer at each element corresponds to the correct class. In our case, the \"correct\" class labels are class 0, class 1, and class 1.\n",
    "\n",
    "Try out the loss function on three toy predictions. The true class labels are $y=[1,1,0]$. The first two examples correspond to predictions that are \"correct\" in that they have higher raw scores for the correct class. The second example is \"more confident\" in the prediction, leading to a smaller loss. The last two examples are incorrect predictions with lower and higher confidence respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "ALoGYsu1MTiU",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1269)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "input = torch.tensor([[-1., 1],[-1, 1],[1, -1]]) # raw scores correspond to the correct class\n",
    "# input = torch.tensor([[-3., 3],[-3, 3],[3, -3]]) # raw scores correspond to the correct class with higher confidence\n",
    "# input = torch.tensor([[1., -1],[1, -1],[-1, 1]]) # raw scores correspond to the incorrect class\n",
    "# input = torch.tensor([[3., -3],[3, -3],[-3, 3]]) # raw scores correspond to the incorrect class with incorrectly placed confidence\n",
    "\n",
    "target = torch.tensor([1, 1, 0])\n",
    "output = loss(input, target)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCwLf9C2MTiY"
   },
   "source": [
    "## Learning rate schedulers\n",
    "\n",
    "Often we do not want to use a fixed learning rate throughout all training. PyTorch offers learning rate schedulers to change the learning rate over time. Common strategies include multiplying the lr by a constant every epoch (e.g. 0.9) and halving the learning rate when the training loss flattens out.\n",
    "\n",
    "See the [learning rate scheduler docs](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) for usage and examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrapEC2XMTiY"
   },
   "source": [
    "## Convolutions\n",
    "When working with images, we often want to use convolutions to extract features using convolutions. PyTorch implments this for us in the `torch.nn.Conv2d` module. It expects the input to have a specific dimension $(N, C_{in}, H_{in}, W_{in})$ where $N$ is batch size, $C_{in}$ is the number of channels the image has, and $H_{in}, W_{in}$ are the image height and width respectively.\n",
    "\n",
    "We can modify the convolution to have different properties with the parameters:\n",
    "- kernel_size\n",
    "- stride\n",
    "- padding\n",
    "\n",
    "They can change the output dimension so be careful.\n",
    "\n",
    "See the [`torch.nn.Conv2d` docs](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gKSeJYuMTiZ"
   },
   "source": [
    "To illustrate what the `Conv2d` module is doing, let's set the conv weights manually to a Gaussian blur kernel.\n",
    "\n",
    "We can see that it applies the kernel to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "QJjlv1lOMTiZ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# an entire mnist digit\n",
    "image = np.array([0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.3803922 , 0.37647063, 0.3019608 ,0.46274513, 0.2392157 , 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.3529412 , 0.5411765 , 0.9215687 ,0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,0.9215687 , 0.74509805, 0.08235294, 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.54901963,0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.7411765 , 0.09019608, 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.8862746 , 0.9960785 , 0.81568635,0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,0.08235294, 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.14901961, 0.32156864, 0.0509804 , 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.13333334,0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.32941177, 0.9960785 ,0.9960785 , 0.9176471 , 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.4156863 , 0.6156863 ,0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.94117653, 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.26666668, 0.4666667 , 0.86274517,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.14509805, 0.73333335,0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,0.9960785 , 0.9960785 , 0.45882356, 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,0.45098042, 0.34901962, 0.12156864, 0., 0.,0., 0., 0.7843138 , 0.9960785 , 0.9450981 ,0.16078432, 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.6627451 , 0.9960785 ,0.6901961 , 0.24313727, 0., 0., 0.,0., 0., 0., 0., 0.18823531,0.9058824 , 0.9960785 , 0.9176471 , 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0.07058824, 0.48627454, 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.32941177, 0.9960785 , 0.9960785 ,0.6509804 , 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.8235295 , 0.9803922 , 0.9960785 ,0.65882355, 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.34901962, 0.9843138 , 0.9450981 ,0.3372549 , 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.01960784,0.8078432 , 0.96470594, 0.6156863 , 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0.01568628, 0.45882356, 0.27058825,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0., 0.,0., 0., 0., 0.], dtype=np.float32)\n",
    "image_torch = torch.from_numpy(image).view(1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "28-oVco6MTib",
    "outputId": "19ef863a-74fc-4697-a2e1-2c525ea74a24",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a gaussian blur kernel\n",
    "gaussian_kernel = torch.tensor([[1., 2, 1],[2, 4, 2],[1, 2, 1]]) / 16.0\n",
    "\n",
    "conv = nn.Conv2d(1, 1, 3)\n",
    "# manually set the conv weight\n",
    "conv.weight.data[:] = gaussian_kernel\n",
    "\n",
    "convolved = conv(image_torch)\n",
    "\n",
    "plt.title('original image')\n",
    "plt.imshow(image_torch.view(28,28).detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "plt.title('blurred image')\n",
    "plt.imshow(convolved.view(26,26).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhf848TRMTid"
   },
   "source": [
    "As we can see, the image is blurred as expected. \n",
    "\n",
    "In practice, we learn many kernels at a time. In this example, we take in an RGB image (3 channels) and output a 16 channel image. After an activation function, that could be used as input to another `Conv2d` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "noG9FyJ0MTie",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im shape torch.Size([4, 3, 32, 32])\n",
      "convolved im shape torch.Size([4, 16, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "im_channels = 3 # if we are working with RGB images, there are 3 input channels, with black and white, 1\n",
    "out_channels = 16 # this is a hyperparameter we can tune\n",
    "kernel_size = 3 # this is another hyperparameter we can tune\n",
    "batch_size = 4\n",
    "image_width = 32\n",
    "image_height = 32\n",
    "\n",
    "im = torch.randn(batch_size, im_channels, image_width, image_height)\n",
    "\n",
    "m = nn.Conv2d(im_channels, out_channels, kernel_size)\n",
    "convolved = m(im) # it is a module so we can call it\n",
    "\n",
    "print('im shape', im.shape)\n",
    "print('convolved im shape', convolved.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwsmNTYLMTig"
   },
   "source": [
    "## Useful links:\n",
    "- [60 minute PyTorch Tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "- [PyTorch Docs](https://pytorch.org/docs/stable/index.html)\n",
    "- [Lecture notes on Auto-Diff](https://courses.cs.washington.edu/courses/cse446/19wi/notes/auto-diff.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d77LgKaMTih"
   },
   "source": [
    "\n",
    "Custom Datasets, DataLoaders\n",
    "===================================================\n",
    "This is modified from pytorch official tutorial.\n",
    "**Author**: `Sasank Chilamkurthy <https://chsasank.github.io>`_\n",
    "\n",
    "A lot of effort in solving any machine learning problem goes in to\n",
    "preparing the data. PyTorch provides many tools to make data loading\n",
    "easy and hopefully, to make your code more readable. In this tutorial,\n",
    "we will see how to load and preprocess/augment data from a non trivial\n",
    "dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyN-mHRoMTii"
   },
   "source": [
    "Dataset class\n",
    "-------------\n",
    "\n",
    "``torch.utils.data.Dataset`` is an abstract class representing a\n",
    "dataset.\n",
    "Your custom dataset should inherit ``Dataset`` and override the following\n",
    "methods:\n",
    "\n",
    "-  ``__len__`` so that ``len(dataset)`` returns the size of the dataset.\n",
    "-  ``__getitem__`` to support the indexing such that ``dataset[i]`` can\n",
    "   be used to get $i$\\ th sample\n",
    "\n",
    "Let's create a dataset class for our face landmarks dataset. We will\n",
    "read the csv in ``__init__`` but leave the reading of images to\n",
    "``__getitem__``. This is memory efficient because all the images are not\n",
    "stored in the memory at once but read as required.\n",
    "\n",
    "Sample of our dataset will be a dict\n",
    "``{'image': image, 'landmarks': landmarks}``. Our dataset will take an\n",
    "optional argument ``transform`` so that any required processing can be\n",
    "applied on the sample. We will see the usefulness of ``transform`` in the\n",
    "next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "I302HaeiMTij",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class FakeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    # 重写__len__方法\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    # 重写__getitem__方法\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOgpiQcIMTik"
   },
   "source": [
    "However, we are losing a lot of features by using a simple ``for`` loop to\n",
    "iterate over the data. In particular, we are missing out on:\n",
    "\n",
    "-  Batching the data\n",
    "-  Shuffling the data\n",
    "-  Load the data in parallel using ``multiprocessing`` workers.\n",
    "\n",
    "``torch.utils.data.DataLoader`` is an iterator which provides all these\n",
    "features. Parameters used below should be clear. One parameter of\n",
    "interest is ``collate_fn``. You can specify how exactly the samples need\n",
    "to be batched using ``collate_fn``. However, default collate should work\n",
    "fine for most use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TMHL8d06MTik",
    "outputId": "a5fc7f8a-0364-43fa-bf4c-bf63b9c71881",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[0.1607, 0.7505, 0.2195, 0.4503, 0.2654, 0.9002, 0.1130, 0.6207, 0.9174,\n",
      "         0.7816],\n",
      "        [0.2179, 0.2188, 0.0761, 0.7797, 0.6282, 0.8648, 0.8658, 0.8988, 0.1023,\n",
      "         0.9849],\n",
      "        [0.0537, 0.5879, 0.3649, 0.6524, 0.8759, 0.7746, 0.1006, 0.7056, 0.8833,\n",
      "         0.2490],\n",
      "        [0.9677, 0.6395, 0.3386, 0.8322, 0.5141, 0.8169, 0.7245, 0.9103, 0.3337,\n",
      "         0.7093]], dtype=torch.float64), tensor([0.9141, 0.6989, 0.8920, 0.8361], dtype=torch.float64)]\n",
      "1 [tensor([[0.1199, 0.3171, 0.9741, 0.4024, 0.7426, 0.7728, 0.3034, 0.5694, 0.2532,\n",
      "         0.0953],\n",
      "        [0.2178, 0.6931, 0.3243, 0.1248, 0.8160, 0.0812, 0.9456, 0.4411, 0.6673,\n",
      "         0.8855],\n",
      "        [0.0222, 0.7780, 0.8322, 0.3779, 0.7760, 0.8579, 0.8292, 0.6530, 0.7804,\n",
      "         0.3632],\n",
      "        [0.4941, 0.8132, 0.9649, 0.2643, 0.9855, 0.4095, 0.3792, 0.7913, 0.0572,\n",
      "         0.1508]], dtype=torch.float64), tensor([0.6302, 0.7877, 0.8783, 0.3975], dtype=torch.float64)]\n",
      "2 [tensor([[0.3284, 0.1696, 0.7844, 0.2459, 0.8100, 0.2989, 0.7312, 0.8574, 0.5384,\n",
      "         0.5413],\n",
      "        [0.8245, 0.9724, 0.4166, 0.9138, 0.7882, 0.4478, 0.1009, 0.7542, 0.8365,\n",
      "         0.5340],\n",
      "        [0.4703, 0.8940, 0.0488, 0.6189, 0.2165, 0.3690, 0.1559, 0.0179, 0.4059,\n",
      "         0.8598],\n",
      "        [0.2134, 0.0719, 0.7553, 0.8922, 0.8821, 0.0230, 0.8871, 0.6645, 0.5685,\n",
      "         0.8676]], dtype=torch.float64), tensor([0.6684, 0.3896, 0.1687, 0.2481], dtype=torch.float64)]\n",
      "3 [tensor([[0.5278, 0.8160, 0.1592, 0.3736, 0.5514, 0.3135, 0.5063, 0.4535, 0.3171,\n",
      "         0.7263],\n",
      "        [0.3766, 0.3765, 0.9704, 0.2857, 0.9978, 0.1401, 0.0230, 0.3522, 0.2517,\n",
      "         0.1157],\n",
      "        [0.7834, 0.4351, 0.8018, 0.5510, 0.5148, 0.8170, 0.9999, 0.8809, 0.1459,\n",
      "         0.3732],\n",
      "        [0.4141, 0.3726, 0.1592, 0.7814, 0.1712, 0.4631, 0.2933, 0.9528, 0.5704,\n",
      "         0.0166]], dtype=torch.float64), tensor([0.3467, 0.3505, 0.0707, 0.9622], dtype=torch.float64)]\n",
      "4 [tensor([[0.8323, 0.8700, 0.5454, 0.8450, 0.5149, 0.0419, 0.1791, 0.7031, 0.6744,\n",
      "         0.3220],\n",
      "        [0.6361, 0.4606, 0.0143, 0.6765, 0.6592, 0.9844, 0.3884, 0.7085, 0.0863,\n",
      "         0.7014],\n",
      "        [0.1860, 0.4273, 0.5358, 0.3842, 0.6310, 0.4092, 0.6349, 0.4367, 0.8672,\n",
      "         0.8369],\n",
      "        [0.6481, 0.4837, 0.6238, 0.0587, 0.0331, 0.3841, 0.9800, 0.2100, 0.3863,\n",
      "         0.7235]], dtype=torch.float64), tensor([0.9322, 0.1040, 0.6606, 0.5265], dtype=torch.float64)]\n",
      "5 [tensor([[0.2281, 0.3889, 0.7283, 0.8118, 0.1603, 0.7216, 0.4033, 0.5441, 0.0599,\n",
      "         0.4258],\n",
      "        [0.9707, 0.0188, 0.5668, 0.1875, 0.6269, 0.7935, 0.7540, 0.3777, 0.2471,\n",
      "         0.1371],\n",
      "        [0.4584, 0.6084, 0.0251, 0.4538, 0.3208, 0.0994, 0.4381, 0.3062, 0.8947,\n",
      "         0.2294],\n",
      "        [0.3499, 0.1111, 0.6992, 0.6656, 0.7807, 0.9463, 0.1385, 0.4635, 0.3963,\n",
      "         0.2516]], dtype=torch.float64), tensor([0.8010, 0.1657, 0.6911, 0.7250], dtype=torch.float64)]\n",
      "6 [tensor([[0.7063, 0.5142, 0.8462, 0.2278, 0.5691, 0.3350, 0.0752, 0.6063, 0.6071,\n",
      "         0.5078],\n",
      "        [0.3365, 0.2944, 0.9589, 0.4287, 0.7387, 0.8615, 0.7769, 0.2260, 0.6835,\n",
      "         0.5841],\n",
      "        [0.9180, 0.2486, 0.2387, 0.1588, 0.0625, 0.4688, 0.3436, 0.4192, 0.3113,\n",
      "         0.4520],\n",
      "        [0.0486, 0.3099, 0.2459, 0.3697, 0.4683, 0.5009, 0.8411, 0.7312, 0.7374,\n",
      "         0.7078]], dtype=torch.float64), tensor([0.9611, 0.5821, 0.4022, 0.0606], dtype=torch.float64)]\n",
      "7 [tensor([[0.6093, 0.6919, 0.5191, 0.3178, 0.7581, 0.9166, 0.7217, 0.6600, 0.7176,\n",
      "         0.7177],\n",
      "        [0.3043, 0.3251, 0.9747, 0.2892, 0.4350, 0.6477, 0.5327, 0.6246, 0.8091,\n",
      "         0.8018],\n",
      "        [0.1383, 0.7502, 0.2321, 0.8971, 0.2679, 0.0072, 0.6550, 0.4960, 0.0865,\n",
      "         0.5020],\n",
      "        [0.2928, 0.1459, 0.8182, 0.8807, 0.4456, 0.8588, 0.1370, 0.6371, 0.0764,\n",
      "         0.2433]], dtype=torch.float64), tensor([0.7984, 0.8924, 0.0693, 0.7028], dtype=torch.float64)]\n",
      "8 [tensor([[0.2565, 0.6425, 0.8749, 0.9976, 0.8385, 0.5114, 0.2276, 0.6648, 0.9016,\n",
      "         0.6078],\n",
      "        [0.5832, 0.1622, 0.5022, 0.7721, 0.5756, 0.5049, 0.9017, 0.8752, 0.3017,\n",
      "         0.0071],\n",
      "        [0.4811, 0.8527, 0.0389, 0.4001, 0.5017, 0.7988, 0.9515, 0.2554, 0.4967,\n",
      "         0.6661],\n",
      "        [0.3562, 0.9176, 0.0538, 0.4041, 0.2108, 0.7166, 0.4684, 0.6445, 0.6140,\n",
      "         0.0448]], dtype=torch.float64), tensor([0.3772, 0.6017, 0.0142, 0.2131], dtype=torch.float64)]\n",
      "9 [tensor([[0.5302, 0.4012, 0.9036, 0.7497, 0.0773, 0.5403, 0.1657, 0.5247, 0.6464,\n",
      "         0.1044],\n",
      "        [0.4918, 0.2070, 0.6867, 0.7952, 0.2733, 0.3927, 0.3428, 0.8650, 0.6287,\n",
      "         0.1225],\n",
      "        [0.5394, 0.3480, 0.7672, 0.4830, 0.2430, 0.6830, 0.1650, 0.7154, 0.2040,\n",
      "         0.8397],\n",
      "        [0.4781, 0.4152, 0.9875, 0.6821, 0.1392, 0.8361, 0.7345, 0.7701, 0.2741,\n",
      "         0.6083]], dtype=torch.float64), tensor([0.9963, 0.2781, 0.0107, 0.4270], dtype=torch.float64)]\n",
      "10 [tensor([[0.7990, 0.9585, 0.7391, 0.1463, 0.7224, 0.7470, 0.1109, 0.3679, 0.4804,\n",
      "         0.9057],\n",
      "        [0.6183, 0.4390, 0.2234, 0.2672, 0.3253, 0.0996, 0.3329, 0.3624, 0.0687,\n",
      "         0.7545],\n",
      "        [0.1569, 0.6779, 0.1276, 0.9790, 0.5179, 0.8753, 0.2036, 0.7555, 0.0087,\n",
      "         0.8718],\n",
      "        [0.3338, 0.5260, 0.6664, 0.5133, 0.6059, 0.1747, 0.4809, 0.7828, 0.7070,\n",
      "         0.1904]], dtype=torch.float64), tensor([0.2378, 0.9962, 0.1700, 0.0540], dtype=torch.float64)]\n",
      "11 [tensor([[0.2154, 0.9916, 0.6741, 0.1525, 0.6672, 0.4582, 0.9611, 0.7627, 0.7507,\n",
      "         0.6440],\n",
      "        [0.8961, 0.6523, 0.2506, 0.9272, 0.3538, 0.9169, 0.5892, 0.2640, 0.7611,\n",
      "         0.3877],\n",
      "        [0.0377, 0.1846, 0.2351, 0.6739, 0.1233, 0.2511, 0.0408, 0.3672, 0.4464,\n",
      "         0.8181],\n",
      "        [0.7644, 0.7172, 0.4273, 0.4320, 0.5338, 0.6517, 0.4314, 0.8056, 0.9279,\n",
      "         0.0460]], dtype=torch.float64), tensor([0.6375, 0.8398, 0.9458, 0.5671], dtype=torch.float64)]\n",
      "12 [tensor([[0.8237, 0.7196, 0.7745, 0.6362, 0.1759, 0.1344, 0.5206, 0.1612, 0.2106,\n",
      "         0.6986],\n",
      "        [0.8054, 0.2658, 0.8679, 0.9119, 0.5494, 0.6236, 0.0299, 0.5348, 0.9124,\n",
      "         0.1893],\n",
      "        [0.6016, 0.4448, 0.2847, 0.7547, 0.3352, 0.0282, 0.0265, 0.7694, 0.2919,\n",
      "         0.0418],\n",
      "        [0.0032, 0.8392, 0.2040, 0.3064, 0.5418, 0.4013, 0.9537, 0.6161, 0.7079,\n",
      "         0.7098]], dtype=torch.float64), tensor([0.3227, 0.6959, 0.9485, 0.8609], dtype=torch.float64)]\n",
      "13 [tensor([[0.7413, 0.2733, 0.5827, 0.2214, 0.4748, 0.4406, 0.3101, 0.5876, 0.0129,\n",
      "         0.6003],\n",
      "        [0.3559, 0.2520, 0.8395, 0.2757, 0.4455, 0.3827, 0.0265, 0.3593, 0.8669,\n",
      "         0.7945],\n",
      "        [0.7426, 0.3770, 0.1523, 0.9865, 0.2812, 0.8682, 0.9326, 0.5801, 0.7706,\n",
      "         0.5985],\n",
      "        [0.5693, 0.5644, 0.5866, 0.2517, 0.5743, 0.6929, 0.5672, 0.0552, 0.4038,\n",
      "         0.5957]], dtype=torch.float64), tensor([0.4842, 0.2308, 0.5679, 0.7777], dtype=torch.float64)]\n",
      "14 [tensor([[0.8114, 0.3428, 0.0302, 0.8012, 0.5500, 0.9757, 0.9377, 0.1723, 0.9910,\n",
      "         0.8823],\n",
      "        [0.4941, 0.6465, 0.5658, 0.5901, 0.5958, 0.4338, 0.3983, 0.5382, 0.4218,\n",
      "         0.7675],\n",
      "        [0.6247, 0.1206, 0.4379, 0.9859, 0.2764, 0.4106, 0.9155, 0.7328, 0.4502,\n",
      "         0.5232],\n",
      "        [0.0701, 0.5967, 0.9111, 0.6512, 0.4111, 0.4676, 0.4478, 0.9842, 0.8404,\n",
      "         0.4056]], dtype=torch.float64), tensor([0.1123, 0.0496, 0.7688, 0.5902], dtype=torch.float64)]\n",
      "15 [tensor([[0.8191, 0.8489, 0.1772, 0.9085, 0.0058, 0.8331, 0.7013, 0.2994, 0.7229,\n",
      "         0.8936],\n",
      "        [0.3540, 0.0011, 0.8606, 0.7875, 0.5722, 0.5466, 0.2267, 0.8504, 0.3918,\n",
      "         0.4944],\n",
      "        [0.4571, 0.8427, 0.5835, 0.3360, 0.3925, 0.7490, 0.6768, 0.8759, 0.8813,\n",
      "         0.5227],\n",
      "        [0.5835, 0.8095, 0.3585, 0.1956, 0.9125, 0.4859, 0.9486, 0.4849, 0.0836,\n",
      "         0.4166]], dtype=torch.float64), tensor([0.1087, 0.5605, 0.8901, 0.9385], dtype=torch.float64)]\n",
      "16 [tensor([[0.4138, 0.6663, 0.6801, 0.0039, 0.5793, 0.5202, 0.2730, 0.5786, 0.4224,\n",
      "         0.6450],\n",
      "        [0.4951, 0.3761, 0.8858, 0.7965, 0.0790, 0.4192, 0.6889, 0.2788, 0.2703,\n",
      "         0.7588],\n",
      "        [0.7620, 0.1762, 0.7459, 0.0526, 0.0959, 0.1263, 0.2974, 0.5547, 0.7655,\n",
      "         0.4268],\n",
      "        [0.3044, 0.0510, 0.7264, 0.7543, 0.8874, 0.8899, 0.3413, 0.2838, 0.6987,\n",
      "         0.9671]], dtype=torch.float64), tensor([0.4509, 0.8316, 0.8821, 0.8890], dtype=torch.float64)]\n",
      "17 [tensor([[0.7867, 0.0368, 0.9206, 0.9337, 0.8809, 0.9017, 0.9559, 0.0748, 0.7541,\n",
      "         0.3554],\n",
      "        [0.1971, 0.8266, 0.2606, 0.8751, 0.9284, 0.0025, 0.4271, 0.0287, 0.3434,\n",
      "         0.8008],\n",
      "        [0.0369, 0.1112, 0.5341, 0.9180, 0.1229, 0.2131, 0.9884, 0.2413, 0.1455,\n",
      "         0.3931],\n",
      "        [0.4315, 0.7719, 0.1310, 0.3391, 0.4141, 0.8267, 0.8796, 0.8411, 0.6632,\n",
      "         0.1833]], dtype=torch.float64), tensor([0.3912, 0.1560, 0.5540, 0.7325], dtype=torch.float64)]\n",
      "18 [tensor([[0.3578, 0.9249, 0.0381, 0.5131, 0.1206, 0.7129, 0.4546, 0.8716, 0.5205,\n",
      "         0.9073],\n",
      "        [0.4503, 0.8991, 0.3868, 0.5059, 0.8107, 0.4437, 0.3186, 0.8296, 0.3045,\n",
      "         0.9638],\n",
      "        [0.1161, 0.7233, 0.1258, 0.3029, 0.2641, 0.0181, 0.3414, 0.9805, 0.5464,\n",
      "         0.3527],\n",
      "        [0.7571, 0.1026, 0.9518, 0.9861, 0.7659, 0.3394, 0.8519, 0.7071, 0.6117,\n",
      "         0.0923]], dtype=torch.float64), tensor([0.6153, 0.4832, 0.2787, 0.0513], dtype=torch.float64)]\n",
      "19 [tensor([[0.2557, 0.3764, 0.4861, 0.9708, 0.7652, 0.3815, 0.2673, 0.9198, 0.3272,\n",
      "         0.8305],\n",
      "        [0.3614, 0.9278, 0.9113, 0.6287, 0.8299, 0.0714, 0.9882, 0.3744, 0.3404,\n",
      "         0.4365],\n",
      "        [0.7345, 0.8872, 0.8974, 0.3731, 0.7883, 0.2165, 0.8474, 0.5976, 0.7340,\n",
      "         0.9752],\n",
      "        [0.5436, 0.3181, 0.0323, 0.1262, 0.8260, 0.6836, 0.0255, 0.3964, 0.3774,\n",
      "         0.1964]], dtype=torch.float64), tensor([0.0659, 0.0662, 0.8677, 0.4678], dtype=torch.float64)]\n",
      "20 [tensor([[0.4932, 0.6193, 0.7225, 0.3658, 0.3154, 0.8009, 0.1131, 0.5378, 0.5661,\n",
      "         0.9024],\n",
      "        [0.8998, 0.3457, 0.3010, 0.8696, 0.0501, 0.1486, 0.5430, 0.9186, 0.2304,\n",
      "         0.7917],\n",
      "        [0.4552, 0.7650, 0.1902, 0.7383, 0.1934, 0.0834, 0.5219, 0.2521, 0.6284,\n",
      "         0.5261],\n",
      "        [0.5461, 0.4479, 0.5276, 0.9328, 0.6250, 0.1592, 0.5453, 0.9185, 0.9443,\n",
      "         0.5115]], dtype=torch.float64), tensor([0.4561, 0.6607, 0.9525, 0.9596], dtype=torch.float64)]\n",
      "21 [tensor([[0.5327, 0.2521, 0.7249, 0.0415, 0.7415, 0.8456, 0.6358, 0.0870, 0.9702,\n",
      "         0.4829],\n",
      "        [0.1742, 0.9428, 0.3511, 0.0318, 0.8320, 0.4126, 0.5260, 0.5314, 0.4775,\n",
      "         0.3001],\n",
      "        [0.0826, 0.0401, 0.3765, 0.5377, 0.2901, 0.6345, 0.7636, 0.4199, 0.2165,\n",
      "         0.7943],\n",
      "        [0.0811, 0.5981, 0.7371, 0.7393, 0.7330, 0.2002, 0.1863, 0.6912, 0.8983,\n",
      "         0.2225]], dtype=torch.float64), tensor([0.3605, 0.7152, 0.6061, 0.1581], dtype=torch.float64)]\n",
      "22 [tensor([[0.5528, 0.3880, 0.6852, 0.8118, 0.1572, 0.4051, 0.5523, 0.3418, 0.3813,\n",
      "         0.0562],\n",
      "        [0.7362, 0.6828, 0.9567, 0.9382, 0.4811, 0.3479, 0.9309, 0.3533, 0.2270,\n",
      "         0.6336],\n",
      "        [0.3886, 0.8890, 0.2710, 0.2204, 0.5277, 0.8907, 0.4083, 0.2466, 0.8493,\n",
      "         0.2587],\n",
      "        [0.0864, 0.6843, 0.4691, 0.1756, 0.3991, 0.9136, 0.9102, 0.5311, 0.0342,\n",
      "         0.2853]], dtype=torch.float64), tensor([0.1379, 0.2997, 0.2773, 0.6930], dtype=torch.float64)]\n",
      "23 [tensor([[0.6782, 0.0100, 0.5527, 0.4749, 0.8026, 0.6173, 0.2771, 0.1990, 0.2314,\n",
      "         0.2683],\n",
      "        [0.5373, 0.7023, 0.6300, 0.4541, 0.7928, 0.2727, 0.7587, 0.7080, 0.3412,\n",
      "         0.0397],\n",
      "        [0.8986, 0.2561, 0.6633, 0.0073, 0.8985, 0.0367, 0.7790, 0.6322, 0.6048,\n",
      "         0.7243],\n",
      "        [0.4920, 0.0658, 0.8194, 0.5104, 0.8347, 0.0747, 0.8825, 0.9006, 0.8617,\n",
      "         0.9923]], dtype=torch.float64), tensor([0.1097, 0.5084, 0.7629, 0.5202], dtype=torch.float64)]\n",
      "24 [tensor([[0.8207, 0.7724, 0.6158, 0.2717, 0.6622, 0.3365, 0.6771, 0.0998, 0.9377,\n",
      "         0.2384],\n",
      "        [0.9757, 0.6648, 0.7296, 0.4929, 0.4648, 0.0073, 0.5707, 0.2130, 0.8451,\n",
      "         0.6268],\n",
      "        [0.0757, 0.3211, 0.3277, 0.6567, 0.3957, 0.8897, 0.7743, 0.9833, 0.3481,\n",
      "         0.3315],\n",
      "        [0.3637, 0.4021, 0.4722, 0.2514, 0.8839, 0.4806, 0.9773, 0.9450, 0.6619,\n",
      "         0.9591]], dtype=torch.float64), tensor([0.1714, 0.2919, 0.6697, 0.7184], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 10)\n",
    "y = np.random.rand(100)\n",
    "\n",
    "dataset = FakeDataset(x, y)\n",
    "\n",
    "# batch_size=4  100个数据按4个一捆，分成25捆\n",
    "dataloader = DataLoader(dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-m-ml0NoMTim"
   },
   "source": [
    "Mixed Presision Training\n",
    "===================================================\n",
    "**Author**: `Chi-Liang Liu <https://liangtaiwan.github.io>`\n",
    "**Ref**: https://github.com/NVIDIA/apex\n",
    "Using mixed precision to train your networks can be:\n",
    "- 2-4x faster\n",
    "- memory-efficient\n",
    "in only 3 lines of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a94qxAC_MTin"
   },
   "source": [
    "# Apex \n",
    "\n",
    "NVIDIA-maintained utilities to streamline mixed precision and distributed training in Pytorch. Some of the code here will be included in upstream Pytorch eventually. The intention of Apex is to make up-to-date utilities available to users as quickly as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fw6ociH0MTin"
   },
   "source": [
    "## apex.amp\n",
    "\n",
    "Amp allows users to easily experiment with different pure and mixed precision modes.\n",
    "Commonly-used default modes are chosen by\n",
    "selecting an \"optimization level\" or ``opt_level``; each ``opt_level`` establishes a set of\n",
    "properties that govern Amp's implementation of pure or mixed precision training.\n",
    "Finer-grained control of how a given ``opt_level`` behaves can be achieved by passing values for\n",
    "particular properties directly to ``amp.initialize``.  These manually specified values\n",
    "override the defaults established by the ``opt_level``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "IxP-tvHcMTio",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'apex'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-151-f5e8b68ab591>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mapex\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mamp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# Declare model and optimizer as usual, with default (FP32) precision\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLinear\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m100\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0moptimizer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSGD\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1e-3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'apex'"
     ]
    }
   ],
   "source": [
    "from apex import amp\n",
    "\n",
    "# Declare model and optimizer as usual, with default (FP32) precision\n",
    "model = torch.nn.Linear(10, 100).cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Allow Amp to perform casts as required by the opt_level\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n",
    "...\n",
    "# loss.backward() becomes:\n",
    "with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "    scaled_loss.backward()\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [
    "zqyBFdobMTha",
    "jlzoXa6UMThg",
    "l08nQdE9MThp",
    "Tmg4eFQAMThr",
    "jifMOIcNMTh5",
    "aSO1McZLMTiT",
    "OCwLf9C2MTiY",
    "IrapEC2XMTiY",
    "NwsmNTYLMTig",
    "OyN-mHRoMTii"
   ],
   "name": "PyTorch_Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PyCharm (mse-ecnu-py)",
   "language": "python",
   "name": "pycharm-e6849b34"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}